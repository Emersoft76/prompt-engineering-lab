import os
from dotenv import load_dotenv
import streamlit as st
from langchain.chat_models import ChatOpenAI
from langchain.chains import ConversationChain
from langchain.memory import ConversationBufferMemory

# Carrega variÃ¡veis de ambiente
load_dotenv()

st.set_page_config(page_title="ðŸ§  LangChain Chatbot", layout="centered")
st.title("ðŸ’¬ LangChain Chatbot Demo")

# Inicializa memÃ³ria e modelo
memory = ConversationBufferMemory()
llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0.7)

conversation = ConversationChain(llm=llm, memory=memory, verbose=True)

# Interface
user_input = st.text_input("VocÃª:", "")

if user_input:
    output = conversation.run(user_input)
    st.markdown(f"**Assistente:** {output}")
